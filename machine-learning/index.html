<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Mark  Crowley | Machine Learning (ML)</title>
<meta name="description" content="">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/machine-learning/">

<!-- Theming-->


    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Mark</span>   Crowley
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/bio/">
                bio
                
              </a>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/news/">
                news
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
      
          
            <h1 class="post-title">Machine Learning (ML)</h1>
        
      
    <p class="post-description" style="border-bottom-style:dashed; border-bottom-color:lightgrey; border-bottom-width:1px; margin:1px; margin-bottom:10px;">ML is the study of how to build computer programs that can learn to detect patterns from data.</p>

      
      
      
      
      
      
        <p></p>
  </header>

  <article>
      
    <p>In the broadest terms my research spans the areas of <strong><em><a href="/artificial-intelligence/">Artificial Intelligence (AI)</a></em></strong> and <strong><em><a href="/machine-learning/">Machine Learning (ML)</a></em></strong> which can be seen highly related, independent, or identical research fields depending on who you are.</p>

<p>My approach to understanding the relationship is summarized in this picture which I use in <a href="/teaching/">my courses</a> on the subject.</p>

<p><img src="/assets/img/aiml/AIMLimage.png" style="width: 100%; padding: 10px; align: center;" /></p>


  </article>


      
          
            <div class="publications">
              <h2>Our Papers on Machine Learning</h2> 
            <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="ganapathi-subramanian2022ijcai" class="col-sm-8">
    
      <div class="title">Learning from Multiple Independent Advisors in Multi-agent Reinforcement Learning</div>
      <div class="author">
        
          
            
              
                
                  Ganapathi Subramanian, Sriram,
                
              
            
          
        
          
            
              
                
                  Taylor, Mathew,
                
              
            
          
        
          
            
              
                
                  Larson, Kate,
                
              
            
          
        
          
            
              
                and <em>Crowley, Mark</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In International Joint Conference on Artificial Intelligence (IJCAI)</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Multi-agent reinforcement learning typically suffers from the problem of sample efficiency, where learning suitable policies involve the use of many data samples. Learning from external demonstrators is a possible solution for this problem, however almost all previous approaches assume the presence of a single demonstrator that can be followed. Leveraging multiple knowledge sources (broadly ‘advisors’) that have expertise in distinct aspects of the environment could substantially speed up learning in complex environments. In this paper, we study the problem of simultaneously learning from multiple independent advisors in multi-agent reinforcement learning. Particularly, we adapt the two-level Q-learning architecture that was previously introduced for the single-agent setting, to multi-agent environments. We provide principled algorithms that systematically incorporate a set of advisors by evaluating the value of the advisors and using the advisors for action selection. We provide theoretical convergence and sample complexity guarantees. Experimentally, we validate our approach in three different test-beds and show that our algorithms give a stronger performance compared to baselines, can effectively integrate the combined expertise of different advisors, and ignore the bad advisors.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="akgun2022ieeetoac" class="col-sm-8">
    
      <div class="title">Affective Search and Rescue Robots to Improve Robot-to-Human Communication in Robot-Assisted Rescue Teams</div>
      <div class="author">
        
          
            
              
                
                  Akgun, Sami Alperen,
                
              
            
          
        
          
            
              
                
                  Ghafurian, Moojan,
                
              
            
          
        
          
            
              
                <em>Crowley, Mark</em>,
              
            
          
        
          
            
              
                
                  and Dautenhahn, Kerstin
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Affective Computing</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">SubWorld</abbr>
    
  
  </div>

  <div id="beeler2022ieeeintsys" class="col-sm-8">
    
      <div class="title">Dynamic programming with partial information to overcome navigational uncertainty in a nautical environment</div>
      <div class="author">
        
          
            
              
                
                  Beeler, Chris,
                
              
            
          
        
          
            
              
                
                  Li, Xinkai,
                
              
            
          
        
          
            
              
                <em>Crowley, Mark</em>,
              
            
          
        
          
            
              
                
                  Fraser, Maia,
                
              
            
          
        
          
            
              
                
                  and Tamblyn, Isaac
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Intelligent Systems</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Using a toy nautical navigation environment, we show that dynamic
programming can be used when only partial information about a partially
observed Markov decision process (POMDP) is known. By incorporating
uncertainty into our model, we show that navigation policies can be
constructed that maintain safety. Adding controlled sensing methods, we
show that these policies can also lower measurement costs at the same
time.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="bellinger2022ai2ase" class="col-sm-8">
    
      <div class="title">Scientific Discovery and the Cost of Measurement – Balancing Information and Cost in Reinforcement Learning</div>
      <div class="author">
        
          
            
              
                
                  Bellinger, Colin,
                
              
            
          
        
          
            
              
                
                  Drozdyuk, Andriy,
                
              
            
          
        
          
            
              
                <em>Crowley, Mark</em>,
              
            
          
        
          
            
              
                
                  and Tamblyn, Isaac
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 1st Annual AAAI Workshop on AI to Accelerate Science and Engineering (AI2ASE)</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2112.07535" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The use of reinforcement learning (RL) in scientific applications, such as materials design and automated chemistry, is increasing. A major challenge, however, lies in fact that measuring the state of the system is often costly and time consuming in scientific applications, whereas policy learning with RL requires a measurement after each time step. In this work, we make the measurement costs explicit in the form of a costed reward and propose a framework that enables off-the-shelf deep RL algorithms to learn a policy for both selecting actions and determining whether or not to measure the current state of the system at each time step. In this way, the agents learn to balance the need for information with the cost of information. Our results show that when trained under this regime, the Dueling DQN and PPO agents can learn optimal action policies whilst making up to 50% fewer state measurements, and recurrent neural networks can produce a greater than 50% reduction in measurements. We postulate the these reduction can help to lower the barrier to applying RL to real-world scientific applications.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MARLEmpircal</abbr>
    
  
  </div>

  <div id="lee2021frontai" class="col-sm-8">
    
      <div class="title">Investigation of Independent Reinforcement Learning Algorithms in Multi-Agent Environments</div>
      <div class="author">
        
          
            
              
                
                  Lee, Ken Ming,
                
              
            
          
        
          
            
              
                
                  Ganapathi Subramanian, Sriram,
                
              
            
          
        
          
            
              
                and <em>Crowley, Mark</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Frontiers in Artificial Intelligence (Machine Learning and Artificial Intelligence)</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MARLEmpircal</abbr>
    
  
  </div>

  <div id="lee2021neuripsdeeprl" class="col-sm-8">
    
      <div class="title">Investigation of Independent Reinforcement Learning Algorithms in Multi-Agent Environments</div>
      <div class="author">
        
          
            
              
                
                  Lee, Ken Ming,
                
              
            
          
        
          
            
              
                
                  Ganapathi Subramanian, Sriram,
                
              
            
          
        
          
            
              
                and <em>Crowley, Mark</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In NeurIPS 2021 Deep Reinforcement Learning Workshop</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/http://arxiv.org/abs/2111.01100" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Independent reinforcement learning algorithms have no theoretical guarantees for finding the best policy in multi-agent settings. However, in practice, prior works have reported good performance with independent algorithms in some domains and bad performance in others. Moreover, a comprehensive study of the strengths and weaknesses of independent algorithms is lacking in the literature. In this paper, we carry out an empirical comparison of the performance of independent algorithms on four PettingZoo environments that span the three main categories of multi-agent environments, i.e., cooperative, competitive, and mixed. We show that in fully-observable environments, independent algorithms can perform on par with multi-agent algorithms in cooperative and competitive settings. For the mixed environments, we show that agents trained via independent algorithms learn to perform well individually, but fail to learn to cooperate with allies and compete with enemies. We also show that adding recurrence improves the learning of independent algorithms in cooperative partially observable environments.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="crowley2020coviddata" class="col-sm-8">
    
      <div class="title">Prediction and Causality: How Can Machine Learning be Used for COVID-19?</div>
      <div class="author">
        
          
            
              <em>Crowley, Mark</em>
            
          
        
      </div>

      <div class="periodical">
      
        <em>In "What Needs to be done in order to Curb the Spread of Covid-19: Exposure Notification, Legal Considerations, and Statistical Modeling", a Conference on Data and Privacy during a Global Pandemic</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
    
    
    
      
      <a href="/assets/pdf/pdfs/2021-coviddata-crowley-prediction.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
      
      <a href="/assets/pdf/pdfs/2021-coviddata-crowley-prediction.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    
      <a href="https://uwaterloo.ca/master-of-public-service/events/data-and-privacy-during-global-pandemic-conference" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">VTFR-LBFGS-21</abbr>
    
  
  </div>

  <div id="godaz2021acml" class="col-sm-8">
    
      <div class="title">Vector Transport Free Riemannian LBFGS for Optimization on Symmetric Positive Definite Matrix Manifolds</div>
      <div class="author">
        
          
            
              
                
                  Godaz, Reza,
                
              
            
          
        
          
            
              
                
                  <a href="https://uwaterloo.ca/scholar/bghojogh" target="_blank">Ghojogh, Benyamin</a>,
                
              
            
          
        
          
            
              
                
                  Hosseini, Reshad,
                
              
            
          
        
          
            
              
                
                  Monsefi, Reza,
                
              
            
          
        
          
            
              
                
                  Karray, Fakhri,
                
              
            
          
        
          
            
              
                and <em>Crowley, Mark</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Asian Conference on Machine Learning (ACML)</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2108.11019" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="/assets/pdf/2021-acml-godaz-vector1.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
      
      <a href="/assets/pdf/2021-acml-godaz-vector2.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Supp</a>
      
    
    
    
    
      
      <a href="/pdf/2021-acml-godaz-vector3.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    
      <a href="http://www.acml-conf.org/2021/conference/accepted-papers/81/" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This work concentrates on optimization on Riemannian manifolds. The Limited-memory Broyden–Fletcher–Goldfarb–Shanno (LBFGS) algorithm is a commonly used quasi-Newton method for numerical optimization in Euclidean spaces. Riemannian LBFGS (RLBFGS) is an extension of this method to Riemannian manifolds. RLBFGS involves computationally expensive vector transports as well as unfolding recursions using adjoint vector transports. In this article, we propose two mappings in the tangent space using the inverse second root and Cholesky decomposition. These mappings make both vector transport and adjoint vector transport identity and therefore isometric. Identity vector transport makes RLBFGS less computationally expensive and its isometry is also very useful in convergence analysis of RLBFGS. Moreover, under the proposed mappings, the Riemannian metric reduces to Euclidean inner product, which is much less computationally expensive. We focus on the Symmetric Positive Definite (SPD) manifolds which are beneficial in various fields such as data science and statistics. This work opens a research opportunity for extension of the proposed mappings to other well-known manifolds.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="subramanian2018neurips-ai4sg" class="col-sm-8">
    
      <div class="title">A Complementary Approach to Improve WildFire Prediction Systems.</div>
      <div class="author">
        
          
            
              
                
                  Subramanian, Sriram Ganapathi,
                
              
            
          
        
          
            
              
                and <em>Crowley, Mark</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Neural Information Processing Systems (AI for social good workshop)</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
    
    
    
      
      <a href="/assets/pdf/2018-neurips-ai-subramanian-a%20complementary.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="https://aiforsocialgood.github.io/2018/acceptedpapers.htm" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Amrl</abbr>
    
  
  </div>

  <div id="bellinger2021canai" class="col-sm-8">
    
      <div class="title">Active Measure Reinforcement Learning for Observation Cost Minimization: A framework for minimizing measurement costs in reinforcement learning</div>
      <div class="author">
        
          
            
              
                
                  Bellinger, Colin,
                
              
            
          
        
          
            
              
                
                  Coles, Rory,
                
              
            
          
        
          
            
              
                <em>Crowley, Mark</em>,
              
            
          
        
          
            
              
                
                  and Tamblyn, Isaac
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Canadian Conference on Artificial Intelligence</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2005.12697" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="/assets/pdf/2021-canai-bellinger-active%20measure%20reinforcement.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Markov Decision Processes (MDP) with explicit measurement cost are a class of en- vironments in which the agent learns to maximize the costed return. Here, we define the costed return as the discounted sum of rewards minus the sum of the explicit cost of measuring the next state. The RL agent can freely explore the relationship between actions and rewards but is charged each time it measures the next state. Thus, an op- timal agent must learn a policy without making a large number of measurements. We propose the active measure RL framework (Amrl) as a solution to this novel class of problem, and contrast it with standard reinforcement learning under full observability and planning under partially observability. We demonstrate that Amrl-Q agents learn to shift from a reliance on costly measurements to exploiting a learned transition model in order to reduce the number of real-world measurements and achieve a higher costed return. Our results demonstrate the superiority of Amrl-Q over standard RL methods, Q-learning and Dyna-Q, and POMCP for planning under a POMDP in environments with explicit measurement costs.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="sikaroudi2020iscv" class="col-sm-8">
    
      <div class="title">Offline versus Online Triplet Mining based on Extreme Distances of Histopathology Patches</div>
      <div class="author">
        
          
            
              
                
                  Sikaroudi, Milad,
                
              
            
          
        
          
            
              
                
                  <a href="https://uwaterloo.ca/scholar/bghojogh" target="_blank">Ghojogh, Benyamin</a>,
                
              
            
          
        
          
            
              
                
                  Safarpoor, Amir,
                
              
            
          
        
          
            
              
                
                  Karray, Fakhri,
                
              
            
          
        
          
            
              
                <em>Crowley, Mark</em>,
              
            
          
        
          
            
              
                
                  and Tizhoosh, H. R.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 15th International Symposium on Visual Computing (ISCV 2020)</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2007.02200" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="/assets/pdf/2020-iscv-sikaroudi-offline%20versus%20online%20triplet%20mining%20based%20on%20extreme%20distances.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="https://link.springer.com/chapter/10.1007/978-3-030-64556-4_26" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We analyze the effect of offline and online triplet mining for colorectal cancer (CRC) histopathology dataset containing 100,000 patches. We consider the extreme, i.e., farthest and nearest patches with respect to a given anchor, both in online and offline mining. While many works focus solely on how to select the triplets online (batch-wise), we also study the effect of extreme distances and neighbor patches before training in an offline fashion. We analyze the impacts of extreme cases for offline versus online mining, including easy positive, batch semi-hard, and batch hard triplet mining as well as the neighborhood component analysis loss, its proxy version, and distance weighted sampling. We also investigate online approaches based on extreme distance and comprehensively compare the performance of offline and online mining based on the data patterns and explain offline mining as a tractable generalization of the online mining with large mini-batch size. As well, we discuss the relations of different colorectal tissue types in terms of extreme distances. We found that offline mining can generate a better statistical representation of the population by working on the whole dataset.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">iMondrian</abbr>
    
  
  </div>

  <div id="ma2020smc" class="col-sm-8">
    
      <div class="title">Isolation Mondrian Forest for Batch and Online Anomaly Detection</div>
      <div class="author">
        
          
            
              
                
                  Ma, Haoran,
                
              
            
          
        
          
            
              
                
                  <a href="https://uwaterloo.ca/scholar/bghojogh" target="_blank">Ghojogh, Benyamin</a>,
                
              
            
          
        
          
            
              
                
                  Samad, Maria N,
                
              
            
          
        
          
            
              
                
                  Zheng, Dongyu,
                
              
            
          
        
          
            
              
                and <em>Crowley, Mark</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In IEEE International Conference on Systems, Man, and Cybernetics (IEEE-SMC-2020)</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/2020-smc-ma-isolation.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We propose a new method, named isolation Mon- drian forest (iMondrian forest), for batch and online anomaly detection. The proposed method is a novel hybrid of isolation forest and Mondrian forest which are existing methods for batch anomaly detection and online random forest, respectively. iMondrian forest takes the idea of isolation, using the depth of a node in a tree, and implements it in the Mondrian forest structure. The result is a new data structure which can accept streaming data in an online manner while being used for anomaly detection. Our experiments show that iMondrian forest mostly performs better than isolation forest in batch settings and has better or comparable performance against other batch and online anomaly detection methods.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="jain2020review" class="col-sm-8">
    
      <div class="title">A review of machine learning applications in wildfire science and management</div>
      <div class="author">
        
          
            
              
                
                  Jain, Piyush,
                
              
            
          
        
          
            
              
                
                  Coogan, Sean CP,
                
              
            
          
        
          
            
              
                
                  Ganapathi Subramanian, Sriram,
                
              
            
          
        
          
            
              
                <em>Crowley, Mark</em>,
              
            
          
        
          
            
              
                
                  Taylor, Steve,
                
              
            
          
        
          
            
              
                
                  and Flannigan, Mike D
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Environmental Reviews</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2003.00646" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      
      <a href="/assets/pdf/2020-envrevjrnl-jain-review.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
      
      <a href="/assets/pdf/2020-envrevjrnl-jain-review1.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    
      <a href="https://cdnsciencepub.com/doi/10.1139/er-2020-0019" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>
Artificial intelligence has been applied in wildfire science and management since the 1990s, with early applications including neural networks and expert systems. Since then the field has rapidly progressed congruently with the wide adoption of machine learning (ML) methods in the environmental sciences. Here, we present a scoping review of ML applications in wildfire science and management. Our overall objective is to improve awareness of ML methods among wildfire researchers and managers, as well as illustrate the diverse and challenging range of problems in wildfire science available to ML data scientists. To that end, we first present an overview of popular ML approaches used in wildfire science to date, and then review the use of ML in wildfire science as broadly categorized into six problem domains, including: 1) fuels characterization, fire detection, and mapping; 2) fire weather and climate change; 3) fire occurrence, susceptibility, and risk; 4) fire behavior prediction; 5) fire effects; and 6) fire management. Furthermore, we discuss the advantages and limitations of various ML approaches relating to data size, computational requirements, generalizability, and interpretability, as well as identify opportunities for future advances in the science and management of wildfires within a data science context. In total, we identified 298 relevant publications, where the most frequently used ML methods across problem domains included random forests, MaxEnt, artificial neural networks, decision trees, support vector machines, and genetic algorithms. As such, there exists opportunities to apply more current ML methods — including deep learning and agent based learning — in the wildfire sciences, especially in instances involving very large multivariate datasets. We must recognize, however, that despite the ability of ML models to learn on their own, expertise in wildfire science is necessary to ensure realistic modelling of fire processes across multiple scales, while the complexity of some ML methods, such as deep learning, requires a dedicated and sophisticated knowledge of their application. Finally, we stress that the wildfire research and management communities play an active role in providing relevant, high quality, and freely available wildfire data for use by practitioners of ML methods.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="bellinger2020reinforcement" class="col-sm-8">
    
      <div class="title">Reinforcement Learning in a Physics-Inspired Semi-Markov Environment</div>
      <div class="author">
        
          
            
              
                
                  Bellinger, Colin,
                
              
            
          
        
          
            
              
                
                  Coles, Rory,
                
              
            
          
        
          
            
              
                <em>Crowley, Mark</em>,
              
            
          
        
          
            
              
                
                  and Tamblyn, Isaac
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Canadian Conference on Artificial Intelligence</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="garijo2019sciknow" class="col-sm-8">
    
      <div class="title">Semantic Workflows and Machine Learning for the Assessment of Carbon Storage by Urban Trees</div>
      <div class="author">
        
          
            
              
                
                  Carrillo, Juan,
                
              
            
          
        
          
            
              
                
                  Garijo, Daniel,
                
              
            
          
        
          
            
              
                <em>Crowley, Mark</em>,
              
            
          
        
          
            
              
                
                  Gil, Yolanda,
                
              
            
          
        
          
            
              
                
                  and Borda, Katherine
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Third International Workshop on Capturing Scientific Knowledge (Sciknow 2019), Collocated with the tenth International Conference on Knowledge Capture (K-CAP)</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="carrillo2019tac" class="col-sm-8">
    
      <div class="title">Comparison of Deep Learning models for Determining Road Surface Condition from Roadside Camera Images and Weather Data</div>
      <div class="author">
        
          
            
              
                
                  Carrillo, J.,
                
              
            
          
        
          
            
              
                <em>Crowley, M.</em>,
              
            
          
        
          
            
              
                
                  Pan, G.,
                
              
            
          
        
          
            
              
                
                  and Fu, L.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In TAC-ITS Canada Joint Conference</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="https://tac-its.ca/conference-papers/comparison-deep-learning-models-determining-road-surface-condition-roadside-camera" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Road maintenance during the Winter season is a safety critical and resource demanding operation. One of its key activities is determining road surface condition (RSC) in order to prioritize roads and allocate cleaning efforts such as plowing or salting. Two conventional approaches for determining RSC are: visual examination of roadside camera images by trained personnel and patrolling the roads to perform on-site inspections. However, with more than 500 cameras collecting images across Ontario, visual examination becomes a resource-intensive activity, difficult to scale especially during periods of snow storms. This paper presents the preliminary results of an ongoing study focused on improving the efficiency of road maintenance operations. We use multiple Deep Learning models to automatically determine RSC from roadside camera images and weather variables, extending previous research where similar methods have been used to deal with the problem. The dataset we use was collected during the 2017-2018 Winter season from 40 stations connected to the Ontario Road Weather Information System (RWIS), it includes 14.000 labelled images and 70.000 weather measurements. In particular, we train and evaluate the performance of seven state-of-the-art models from the Computer Vision literature, including the recent DenseNet, NASNet, and MobileNet. Also, by integrating observations from weather variables, the models are able to better ascertain RSC under poor visibility conditions.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="nekoeiqachkanloo2019iaai" class="col-sm-8">
    
      <div class="title">Artificial Counselor System For Stock Investment</div>
      <div class="author">
        
          
            
              
                
                  Nekoei Qachkanloo, Hadi,
                
              
            
          
        
          
            
              
                
                  <a href="https://uwaterloo.ca/scholar/bghojogh" target="_blank">Ghojogh, Benyamin</a>,
                
              
            
          
        
          
            
              
                
                  Pasand, Ali Saheb,
                
              
            
          
        
          
            
              
                and <em>Crowley, Mark</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Innovative Applications of Artificial Intelligence (IAAI-19)</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="bhalla2019ecml" class="col-sm-8">
    
      <div class="title">Compact Representation of a Multi-dimensional Combustion Manifold Using Deep Neural Networks</div>
      <div class="author">
        
          
            
              
                
                  Bhalla, Sushrut,
                
              
            
          
        
          
            
              
                
                  Yao, Matthew,
                
              
            
          
        
          
            
              
                
                  Hickey, Jean-Pierre,
                
              
            
          
        
          
            
              
                and <em>Crowley, Mark</em>
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/bhallaECML2019.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
      
      <a href="/pdf/ECML_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
      
      <a href="/assets/pdf/ECML2019_slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The computational challenges in turbulent combustion simulations stem from the physical complexities and multi-scale nature of the problem which make it intractable to compute scaleesolving simulations. For most engineering applications, the large scale separation between the flame (typically submillimeter scale) and the characteristic turbulent flow (typically centimeter or meter scale) allows us to evoke simplifying assumptions–such as done for the flamelet model to precompute all the chemical reactions and map them to a low order manifold. The resulting manifold is then tabulated and looked up at runtime. As the physical complexity of combustion simulations increases (including radiation, soot formation, pressure variations etc.) the dimensionality of the resulting manifold grows which impedes an efficient tabulation and look up. In this paper we present a novel approach to model the multidimensional combustion manifold. We approximate the combustion manifold using a neural network function approximator and use it to predict the temperature and composition of the reaction. We present a novel training procedure which is developed to generate a smooth output curve for temperature over the course of a reaction. We then evaluate our work against the current approach of tabulation with linear interpolation in combustion simulations. We also provide an ablation study of our training procedure in the context of overfitting in our model. The combustion dataset used for the modeling of combustion of H2 and O2 in this work is released alongside this paper.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="carrillo2019carsp" class="col-sm-8">
    
      <div class="title">Integration of Roadside Camera Images and Weather Data for monitoring Winter Road Surface Conditions</div>
      <div class="author">
        
          
            
              
                
                  Carrillo, Juan,
                
              
            
          
        
          
            
              
                and <em>Crowley, Mark</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Canadian Association of Road Safety Professionals (CARSP) Conference</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="http://www.carsp.ca/research/research-papers/research-papers-search/download-info/integration-of-roadside-camera-images-and-weather-data-for-monitoring-winter-road-surface-conditions/" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Background/Context: During the Winter season, real-time monitoring of road surface conditions is critical for the safety of drivers and road maintenance operations. Previous research has evaluated the potential of image classification methods for detecting road snow coverage by processing images from roadside cameras installed in RWIS (Road Weather Information System) stations. However, it is a challenging task due to limitations such as image resolution, camera angle, and illumination. Two common approaches to improve the accuracy of image classification methods are: adding more input features to the model and increasing the number of samples in the training dataset. Additional input features can be weather variables and more sample images can be added by including other roadside cameras. Although RWIS stations are equipped with both cameras and weather measurement instruments, they are only a subset of the total number of roadside cameras installed across transportation networks, most of which do not have weather measurement instruments. Thus, improvements in use of image data could benefit from additional data sources. Aims/Objectives: The first objective of this study is to complete an exploratory data analysis over three data sources in Ontario: RWIS stations, all the other MTO (Ministry of Transportation of Ontario) roadside cameras, and Environment Canada weather stations. The second objective is to determine the feasibility of integrating these three datasets into a more extensive and richer dataset with weather variables as additional features and other MTO roadside cameras as additional sources of images. Methods/Targets: First, we quantify the advantage of adding other MTO roadside cameras using spatial statistics, the number of monitored roads, and the coverage of ecoregions with different climate regimes. We then analyze experimental variograms from the literature and determine the feasibility of using Environment Canada stations and RWIS stations to interpolate weather variables for all the other MTO roadside cameras without weather instruments. Results/Activities: By adding all other MTO cameras as image data sources, the total number of cameras in the dataset increases from 139 to 578 across Ontario. The average distance to the nearest camera decreases from 38.4km to 9.4km, and the number of monitored roads increases approximately four times. Additionally, six times more cameras are available in the four most populated ecoregions in Ontario. The experimental variograms show that it is feasible to interpolate weather variables with reasonable accuracy. Moreover, observations in the three datasets are collected with similar frequency, which facilitates our data integration approach. Discussion/Deliverables: Integrating these three datasets is feasible and can benefit the design and development of automated image classification methods for monitoring road snow coverage. We do not consider data from pavement-embedded sensors, an additional line of research may explore the integration of this data. Our approach can provide actionable insights which can be used to more selectively perform manual patrolling to better identify road surface conditions. Conclusions: Our initial results are promising and demonstrate that additional, image only datasets can be added to road monitoring data by using existing multimodal sensors as ground truth, which will lead to greater performance on the future image classification tasks.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="ganapathisubramanian2018aa" class="col-sm-8">
    
      <div class="title">Decision Assist for Self-Driving Cars</div>
      <div class="author">
        
          
            
              
                
                  Ganapathi Subramanian, Sriram,
                
              
            
          
        
          
            
              
                
                  Sambee, Jaspreet Singh,
                
              
            
          
        
          
            
              
                
                  <a href="https://uwaterloo.ca/scholar/bghojogh" target="_blank">Ghojogh, Benyamin</a>,
                
              
            
          
        
          
            
              
                and <em>Crowley, Mark</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Canadian Conference on Artificial Intelligence</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="https://doi.org/10.1007/978-3-319-89656-4_44" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Research into self-driving cars has grown enormously in the last decade primarily due to the advances in the fields of machine intelligence and image processing. An under-appreciated aspect of self-driving cars is actively avoiding high traffic zones, low visibility zones, and routes with rough weather conditions by learning different conditions and making decisions based on trained experiences. This paper addresses this challenge by introducing a novel hierarchical structure for dynamic path planning and experiential learning for vehicles. A multistage system is proposed for detecting and compensating for weather, lighting, and traffic conditions as well as a novel adaptive path planning algorithm named Checked State A3C. This algorithm improves upon the existing A3C Reinforcement Learning (RL) algorithm by adding state memory which provides the ability to learn an adaptive model of the best decisions to take from experience. \textcopyright Springer International Publishing AG, part of Springer Nature 2018.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="ganapathisubramanian2018frontict" class="col-sm-8">
    
      <div class="title">Using Spatial Reinforcement Learning to Build Forest Wildfire Dynamics Models From Satellite Images</div>
      <div class="author">
        
          
            
              
                
                  Ganapathi Subramanian, Sriram,
                
              
            
          
        
          
            
              
                and <em>Crowley, Mark</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Frontiers in ICT</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      
      <a href="/assets/pdf/2018-frontict-ganapathi%20subramanian-using" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    
      <a href="http://journal.frontiersin.org/article/10.3389/fict.2018.00006/full" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Machine learning algorithms have increased tremendously in power in recent years but have yet to be fully utilized in many ecology and sustainable resource management domains such as wildlife reserve design, forest fire management and invasive species spread. One thing these domains have in common is that they contain dynamics that can be characterized as a Spatially Spreading Process (SSP) which requires many parameters to be set precisely to model the dynamics, spread rates and directional biases of the elements which are spreading. We present related work in Artificial Intelligence and Machine Learning for SSP sustainability domains including forest wildfire prediction. We then introduce a novel approach for learning in SSP domains using Reinforcement Learning (RL) where fire is the agent at any cell in the landscape and the set of actions the fire can take from a location at any point in time includes spreading North, South, East, West or not spreading. This approach inverts the usual RL setup since the dynamics of the corresponding Markov Decision Process (MDP) is a known function for immediate wildfire spread. Meanwhile, we learn an agent policy for a predictive model of the dynamics of a complex spatially-spreading process. Rewards are provided for correctly classifying which cells are on fire or not compared to satellite and other related data. We examine the behaviour of five RL algorithms on this problem: Value Iteration, Policy Iteration, Q-Learning, Monte Carlo Tree Search and Asynchronous Advantage Actor-Critic (A3C). We compare to a Gaussian process based supervised learning approach and discuss the relation of our approach to manually constructed, state-of-the-art methods from forest wildfire modelling. We also discuss the relation of our approach to manually constructed, state-of-the-art methods from forest wildfire modelling. We validate our approach with satellite image data of two massive wildfire events in Northern Alberta, Canada, the Fort McMurray fire of 2016 and the Richardson fire of 2011. The results show that we can learn predictive, agent-based policies as models of spatial dynamics using RL on readily available satellite images that other methods and have many additional advantages in terms of generalizability and interpretability.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="fernick2017rsa" class="col-sm-8">
    
      <div class="title">Big Metadata : Machine Learning on Encrypted Communications</div>
      <div class="author">
        
          
            
              
                
                  Fernick, Jennifer,
                
              
            
          
        
          
            
              
                and <em>Crowley, Mark</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In RSA Conference</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="maryam2017spie" class="col-sm-8">
    
      <div class="title">Application of probabilistically-weighted graphs to image-based diagnosis of Alzheimer’s disease using diffusion MRI</div>
      <div class="author">
        
          
            
              
                
                  Maryam, Syeda,
                
              
            
          
        
          
            
              
                
                  McCrackin, Laura,
                
              
            
          
        
          
            
              
                <em>Crowley, Mark</em>,
              
            
          
        
          
            
              
                
                  Rathi, Yogesh,
                
              
            
          
        
          
            
              
                
                  and Michailovich, Oleg
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of SPIE 101324, Medical Imaging 2017 : Computer-Aided Diagnosis</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2254164" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The world’s aging population has given rise to an increasing awareness towards neurodegenerative disorders, including Alzheimers Disease (AD). Treatment options for AD are currently limited, but it is believed that future success depends on our ability to detect the onset of the disease in its early stages. The most frequently used tools for this include neuropsychological assessments, along with genetic, proteomic, and image-based diagnosis. Recently, the applicability of Diffusion Magnetic Resonance Imaging (dMRI) analysis for early diagnosis of AD has also been reported. The sensitivity of dMRI to the microstructural organization of cerebral tissue makes it particularly well-suited to detecting changes which are known to occur in the early stages of AD. Existing dMRI approaches can be divided into two broad categories: region-based and tract-based. In this work, we propose a new approach, which extends region-based approaches to the simultaneous characterization of multiple brain regions. Given a predefined set of features derived from dMRI data, we compute the probabilistic distances between different brain regions and treat the resulting connectivity pattern as an undirected, fully-connected graph. The characteristics of this graph are then used as markers to discriminate between AD subjects and normal controls (NC). Although in this preliminary work we omit subjects in the prodromal stage of AD, mild cognitive impairment (MCI), our method demonstrates perfect separability between AD and NC subject groups with substantial margin, and thus holds promise for fine-grained stratification of NC, MCI and AD populations.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="taleghan2015jmlr" class="col-sm-8">
    
      <div class="title">PAC Optimal MDP Planning with Application to Invasive Species Management</div>
      <div class="author">
        
          
            
              
                
                  Taleghan, Majid Alkaee,
                
              
            
          
        
          
            
              
                
                  <a href="http://web.engr.oregonstate.edu/~tgd/" target="_blank">Dietterich, Thomas G.</a>,
                
              
            
          
        
          
            
              
                <em>Crowley, Mark</em>,
              
            
          
        
          
            
              
                
                  Hall, Kim,
                
              
            
          
        
          
            
              
                
                  and Albers, H. Jo
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Journal of Machine Learning Research</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="http://jmlr.org/papers/v16/taleghan15a.html" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In a simulator-defined MDP, the Markovian dynamics and rewards are provided in the form of a simulator from which samples can be drawn. This paper studies MDP planning algorithms that attempt to minimize the number of simulator calls before terminating and outputting a policy that is approximately optimal with high probability. The paper introduces two heuristics for efficient exploration and an improved confidence interval that enables earlier termination with probabilis- tic guarantees. We prove that the heuristics and the confidence interval are sound and produce with high probability an approximately optimal policy in polynomial time. Experiments on two benchmark problems and two instances of an invasive species management problem show that the improved confidence intervals and the new search heuristics yield reductions of between 8% and 47% in the number of simulator calls required to reach near-optimal policies.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="crowley2014ieeetoc" class="col-sm-8">
    
      <div class="title">Using equilibrium policy gradients for spatiotemporal planning in forest ecosystem management</div>
      <div class="author">
        
          
            
              <em>Crowley, Mark</em>
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Computers</em>
      
      
        2014
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="http://www.computer.org/csdl/trans/tc/preprint/06514032-abs.html" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Spatiotemporal planning involves making choices at multiple locations in space over some planning horizon to maximize utility and satisfy various constraints. In Forest Ecosystem Management, the problem is to choose actions for thousands of locations each year including harvesting, treating trees for fire or pests, or doing nothing. The utility models could place value on sale of lumber, ecosystem sustainability or employment levels and incorporate legal and logistical constraints on actions such as avoiding large contiguous areas of clearcutting. Simulators developed by forestry researchers provide detailed dynamics but are generally inaccesible black boxes. We model spatiotemporal planning as a factored Markov decision process and present a policy gradient planning algorithm to optimize a stochastic spatial policy using simulated dynamics. It is common in environmental and resource planning to have actions at different locations be spatially interelated, this makes representation and planning challenging. We define a global spatial policy in terms of interacting local policies defining distributions over actions at each location conditioned on actions at nearby locations. Markov chain Monte Carlo simulation is used to sample landscape policies and estimate their gradients. Evaluation is carried out on a forestry planning problem with 1,880 locations using a variety of value models and constraints. Index</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="dietterich2013aaai" class="col-sm-8">
    
      <div class="title">PAC Optimal Planning for Invasive Species Management: Improved Exploration for Reinforcement Learning from Simulator-Defined MDPs</div>
      <div class="author">
        
          
            
              
                
                  <a href="http://web.engr.oregonstate.edu/~tgd/" target="_blank">Dietterich, Thomas G</a>,
                
              
            
          
        
          
            
              
                
                  Alkaee Taleghan, Majid,
                
              
            
          
        
          
            
              
                and <em>Crowley, Mark</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI-2013)</em>
      
      
        2013
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI13/paper/view/6478" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Often the most practical way to define a Markov Decision Process (MDP) is as a simulator that, given a state and an action, produces a resulting state and immediate reward sampled from the corresponding distributions. Simulators in natural resource management can be very expensive to execute, so that the time required to solve such MDPs is dominated by the number of calls to the simulator. This paper presents an algorithm, DDV, that combines improved confidence intervals on the Q values (as in interval estimation) with a novel upper bound on the discounted state occupancy probabilities to intelligently choose state-action pairs to explore. We prove that this algorithm terminates with a policy whose value is within εof the optimal policy (with probability 1−δ) after making only polynomially-many calls to the simulator. Experiments on one benchmark MDP and on an MDP for invasive species management show very large reductions in the number of simulator calls required.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Crowley2013" class="col-sm-8">
    
      <div class="title">Policy Gradient Optimization Using Equilibrium Policies for Spatial Planning Domains</div>
      <div class="author">
        
          
            
              <em>Crowley, Mark</em>
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 13th INFORMS Computing Society Conference</em>
      
      
        2013
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">thesis</abbr>
    
  
  </div>

  <div id="Crowley2011thesis" class="col-sm-8">
    
      <div class="title">Equilibrium Policy Gradients for Spatiotemporal Planning</div>
      <div class="author">
        
          
            
              <em>Crowley, Mark</em>
            
          
        
      </div>

      <div class="periodical">
      
      
        2011
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
      <a href="http://hdl.handle.net/2429/38971" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In spatiotemporal planning, agents choose actions at multiple locations in space over some planning horizon to maximize their utility and satisfy various constraints. In forestry planning, for example, the problem is to choose actions for thousands of locations in the forest each year. The actions at each location could include harvesting trees, treating trees against disease and pests, or doing nothing. A utility model could place value on sale of forest products, ecosystem sustainability or employment levels, and could incorporate legal and logistical constraints such as avoiding large contiguous areas of clearcutting and managing road access. Planning requires a model of the dynamics. Existing simulators developed by forestry researchers can provide detailed models of the dynamics of a forest over time, but these simulators are often not designed for use in automated planning. This thesis presents spatiotemoral planning in terms of factored Markov decision processes. A policy gradient planning algorithm optimizes a stochastic spatial policy using existing simulators for dynamics. When a planning problem includes spatial interaction between locations, deciding on an action to carry out at one location requires considering the actions performed at other locations. This spatial interdependence is common in forestry and other environmental planning problems and makes policy representation and planning challenging. We define a spatial policy in terms of local policies defined as distributions over actions at one location conditioned upon actions at other locations. A policy gradient planning algorithm using this spatial policy is presented which uses Markov Chain Monte Carlo simulation to sample the landscape policy, estimate its gradient and use this gradient to guide policy improvement. Evaluation is carried out on a forestry planning problem with 1880 locations using a variety of value models and constraints. The distribution over joint actions at all locations can be seen as the equilibrium of a cyclic causal model. This equilibrium semantics is compared to Structural Equation Models. We also define an algorithm for approximating the equilibrium distribution for cyclic causal networks which exploits graphical structure and analyse when the algorithm is exact.</p>
    </div>
    
  </div>
</div>
</li></ol>
            </div>
          
      

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2022 Mark  Crowley.
    Based on [*folio](https://github.com/bogoli/-folio) design. Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    Last updated: February 26, 2022.
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  



<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
